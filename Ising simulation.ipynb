{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Ising model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "This code simulates the 2d Ising model using Monte Carlo methods. This is a simple physical problem where we take a square lattice of points with a magnet at each point. These magnets can either point up or down and the interactions are such that neighboring magnets like to be aligned. This would all be very simple if the system were not at finite temperature. The magnets would flip to end up all aligned. However the energy coming from the finite temperature may randomly cause some magnets to flip and perturb the system, which can prevent it from reaching a uniform state. If the temperature is low enough the magnets gradually form bigger and bigger islands where they are aligned and if we wait long enough they all become aligned. If the temperature if high enough the system never uniformizes because there is a balance between wanted flips and unwanted thermal flips. The transition between those two possible outcomes happens at a known temperature of 2.269 degrees (in the units that we use). The goal of the project is to give a picture of the state to a neural network and it can tell us if we are above or below the critical temperature."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The algorithm that is used to simulate the 2d Ising is called Metropolis. The steps go as follows:\n",
    "1. Initialize the lattice randomly with 1 or -1 at each site. 1 is for when the magnet points up and -1 if for when it points down.\n",
    "2. Randomly select a point on the grid. \n",
    "3. Calculate the change in the energy that would occur if we flipped the magnet. The energy is given by $E=-\\sum_{i,j}s_i s_j$, where we sum over all pairs of points on the lattice and $s_i$ is $\\pm 1$. If the change is negative, the system likes the change so the magnet is indeed flipped. If the change is positive, there is still a probability of $e^{-\\frac{\\Delta E}{T}}$ that the magnet gets flipped because of thermal fluctuations. Here $T$ is the temperature and $\\Delta E$ is the change in energy that occurs when we flip the magnet.\n",
    "4. Repeat step 3 for a number of steps equal to the size of a side of the lattice. This is considered as one time step. (This is where we update the value for the magnetization and the energy if interested in these quantites.)\n",
    "5. Repeat steps 3 and 4 for a given number of time steps.\n",
    "6. Plot, print the result.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "After the simulation, we use the results to train a neural network that determines if the state of the Ising system corresponds to a temperature higher or lower than the critical temperature."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Simulation of the Ising model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We first import the usual libraries in order to do the simulation."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "import math as m\n",
    "import random\n",
    "\n",
    "%matplotlib inline"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The first function to create makes a square grid (simply a matrix) of a fixed size with random values at each element taken from -1 or 1. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "def initialize_grid(dim):\n",
    "    '''\n",
    "    Create a dim by dim array of numbers chosen randomly from -1 or 1.\n",
    "    '''\n",
    "    grid = np.random.choice([-1,1], size = (dim,dim))\n",
    "    \n",
    "    return grid"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next we make a function to plot a generic grid and add the option of putting a title. We need to create a color map where -1 is black and 1 is white. This will be useful to visualize results."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def plot_grid(grid, title=None):\n",
    "    '''\n",
    "    Plot grid with -1 being black and 1 being white with an option to add a title.\n",
    "    '''\n",
    "    # Create discrete colormap\n",
    "    cmap = colors.ListedColormap(['black', 'white'])\n",
    "    bounds = [-2,0,2]\n",
    "    norm = colors.BoundaryNorm(bounds, cmap.N)\n",
    "    \n",
    "    # Make plot\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(grid, cmap = cmap, norm=norm)\n",
    "    ax.set_title(title)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "This is a function that computes the magnetization of a grid. This is simply the sum of all the elements and it is useful to classify the phase of the model."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "def compute_magnetization(grid):\n",
    "    return np.sum(grid)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "This is one of the main functions of the algorithm. You give it a grid and two numbers that determine a position on the grid. The function first determines where the neighboring elements are. This is important because the grid has to be periodic so border elements are special. The change in energy due to reversing this element is then computed by adding all the contributions from the neighbors. Each one contributes by $$\\Delta E=2*grid(i, j)*grid(i_{neighbor}, j_{neighbor})$$"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "def energy_change(grid, i, j):\n",
    "    '''\n",
    "    Assums a flip of the spin at position (i,j) on the grid and computes the change of\n",
    "    energy due to it.\n",
    "    Returns the change in energy.\n",
    "    '''\n",
    "    n = grid.shape[0]\n",
    "    if (i==0):\n",
    "        left = n-1\n",
    "    else:\n",
    "        left = i-1\n",
    "    if (i==n-1):\n",
    "        right = 0\n",
    "    else:\n",
    "        right = i+1\n",
    "    if (j==0):\n",
    "        down = n-1\n",
    "    else:\n",
    "        down = j-1\n",
    "    if (j==n-1):\n",
    "        up = 0\n",
    "    else:\n",
    "        up = j+1\n",
    "    dE = 2 * grid[i,j] * (grid[left,j] + grid[right,j] + grid[i,up] + grid[i,down])\n",
    "    return dE"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "This function picks a random element of the grid. The actual output is the indices of the element."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "def random_spin(grid):\n",
    "    '''\n",
    "    Choose randomly the position of one entry in the array grid.\n",
    "    Returns the location of the spin.\n",
    "    '''\n",
    "    n = grid.shape[0]\n",
    "    x_index = random.randint(0, n-1)\n",
    "    y_index = random.randint(0, n-1)\n",
    "    return (x_index, y_index)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "This is the second important function of the algorithm. It first uses the previously defined function to pick a random point on the grid. It then starts by computing the change in energy due to reversing this element by using the previously defined function. If the change is negative the element is indeed flipped. If not there is a probability $e^{-\\Delta E/T}$ that the flip still happens. The output is the grid with (potentially) some random element reversed."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "def spin_flip(grid, T):\n",
    "    '''\n",
    "    Picks randomly one spin on the grid and calculates the change in energy due to flipping the spin.\n",
    "    If change is negative, flip the spin.\n",
    "    If change is positive, flip it only with some probability.\n",
    "    Returns the new grid with the spin potentially flipped.\n",
    "    '''\n",
    "    i, j = random_spin(grid)\n",
    "    delta_E = energy_change(grid, i, j)\n",
    "    if delta_E < 0:\n",
    "        grid[i,j] = -grid[i,j]\n",
    "    elif random.random() < m.exp(-delta_E/T):\n",
    "        grid[i,j] = -grid[i,j]\n",
    "    return grid"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "This is the main function of the simulation where we put everything together to run the algorithm. We start by initialize a random grid. We then run the random flip n times for one time step and then repeat the process for a determined number of time steps. The final grid is returned along with (potentially) the initial and final configurations."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "def ising_simulation(n, T, steps=100, plot=False):\n",
    "    '''\n",
    "    Simulate 2d Ising model.\n",
    "    Inputs:\n",
    "    - n: size of the square lattice is n by n\n",
    "    - T: temperature\n",
    "    - steps: number of flips the algorithm tries to make\n",
    "    - plot: decide if the grid is plotted at the beginning and the end of the simulation\n",
    "    Returns:\n",
    "    - the final grid\n",
    "    - if plot is True, the initial and final grids in two plots\n",
    "    '''\n",
    "    grid = initialize_grid(n)\n",
    "    \n",
    "    if plot==True:\n",
    "        plot_grid(grid, title='Initial grid')\n",
    "        \n",
    "    for i in range(steps):\n",
    "        for i in range(n):\n",
    "            grid = spin_flip(grid, T)\n",
    "            \n",
    "    if plot==True:\n",
    "        plot_grid(grid, title='Final grid')\n",
    "        \n",
    "    return grid"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "ising_simulation(50, 3, 3000, plot=True)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 1,  1,  1, ..., -1, -1,  1],\n",
       "       [ 1, -1,  1, ..., -1, -1,  1],\n",
       "       [-1,  1,  1, ..., -1,  1,  1],\n",
       "       ...,\n",
       "       [-1,  1, -1, ..., -1, -1, -1],\n",
       "       [-1,  1,  1, ...,  1, -1, -1],\n",
       "       [ 1,  1,  1, ..., -1, -1, -1]])"
      ]
     },
     "metadata": {},
     "execution_count": 9
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Generating data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The code that we have so far simulates the Ising model and gives a grid back but we want to automate the production of data. The simulation is ran for different values of temperature evenly spread in a determined interval and for a fixed number of repetitions. The function records the final grids as a list of matrices and it also reshapes these grid into vectors and stacks them together to get the right form necessary for machine learning algorithms. The final step is to record in a vector if the temperature is above or below the critical one. The function prints the iteration as it runs to let us see what is going on."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "def generate_data(size, num_temp, temp_min=0.1, temp_max=5, repeat=1, max_iter=None):\n",
    "    '''\n",
    "    Generate data from simulating the Ising model at different temperatures.\n",
    "    The temperatures are spread equally between temp_min and temp_max.\n",
    "    \n",
    "    Input:\n",
    "    - size: the grid is size x size\n",
    "    - num_temp: number of different temperatures to consider\n",
    "    - temp_min: minimum temperature to take\n",
    "    - temp_max: maximum temperature\n",
    "    - repeat: repeat the calculation for each temperature this number of times\n",
    "    - max_iter: number of time steps in the simulation of the Ising model (default is size^2)\n",
    "    \n",
    "    Output:\n",
    "    - raw_X: list of the arrays obtained from simulating the Ising (there are num_temp*repeat elements)\n",
    "    - X: (num_temp, size^2) array where each line is a vectorized version of the grid and every line is a different run\n",
    "    - y: (num_temp, 1) array that says if the simulation is made above the critical temps (y=1) or below (y=0)\n",
    "    '''\n",
    "    \n",
    "    if max_iter==None:\n",
    "        max_iter = size**2\n",
    "\n",
    "    raw_X = []\n",
    "    X = np.zeros((num_temp*repeat, size**2))\n",
    "    y = np.zeros((num_temp*repeat, 1))\n",
    "    temps = np.linspace(temp_min, temp_max, num = num_temp)\n",
    "\n",
    "    for i in range(repeat):\n",
    "        for j in range(num_temp):\n",
    "            grid = ising_simulation(size, temps[j], max_iter)\n",
    "            raw_X.append(grid)\n",
    "            X[i*num_temp+j,:] = grid.reshape(1,grid.size)\n",
    "            y[i*num_temp+j,:] = (temps[j] > 2.269)\n",
    "            print(i*num_temp+j, end=\"\\r\")\n",
    "    \n",
    "    return raw_X, X, y"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "This generates data to use later to train the neural network for a grid of 25 by 25."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "raw_X, X, y = generate_data(size=25, num_temp=40, repeat=20)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "799\r"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "This uses the same grid and generates less data to use as a dev/test set."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "raw_X_test, X_test, y_test = generate_data(size=25, num_temp=20, repeat=10)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "199\r"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "i = 70\n",
    "plot_grid(raw_X[i])\n",
    "y[i]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([1.])"
      ]
     },
     "metadata": {},
     "execution_count": 13
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Using keras"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we want to train a neural network using keras to predict the labels y from the data X. We first import the necessary libraries and functions."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.regularizers import l2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The first way of doing the training is simply to do it directly. We consider a network with two hidden layers (plus the input and output layers). Since there is a lot of randomness in the training (we don't train long enough to get rid of that) it is better to run the taining many times, keep track of the errors each time and average them at the end. This run uses the optimal hyperparameters found using tuning."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# Initialize list of training and test errors\n",
    "train_errors = []\n",
    "test_errors = []\n",
    "\n",
    "\n",
    "# Loop to run model many times and average over results\n",
    "\n",
    "for i in range(15):\n",
    "\n",
    "    # Print iteration to make sure everything works\n",
    "    print(i, end=\"\\r\")\n",
    "    \n",
    "    # Initialize model\n",
    "    model = Sequential()\n",
    "\n",
    "    # Add hidden layer with 32 units and rlu activation. Add output layer with sigmoid activation.\n",
    "    model.add(Dense(25, activation='relu', kernel_regularizer=l2(0.1), input_dim=25**2))\n",
    "    model.add(Dense(15, activation='relu', kernel_regularizer=l2(0.1)))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Fit model\n",
    "    model.fit(X, y, epochs=40, verbose=0)\n",
    "\n",
    "    # Add training and test errors to lists\n",
    "    train_errors.append(model.evaluate(X,y,verbose=0)[1])\n",
    "    test_errors.append(model.evaluate(X_test,y_test,verbose=0)[1])\n",
    "    \n",
    "# Average errors\n",
    "avg_train_error = np.mean(train_errors)\n",
    "std_train_error = np.std(train_errors)\n",
    "avg_test_error = np.mean(test_errors)\n",
    "std_test_error = np.std(test_errors)\n",
    "\n",
    "print('Average of training errors: '+str(avg_train_error))\n",
    "print('Standard deviation of training errors: '+str(std_train_error))\n",
    "print('Average of test errors: '+str(avg_test_error))\n",
    "print('Standard deviation of test errors: '+str(std_test_error))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Average of training errors: 0.9983333230018616\n",
      "Standard deviation of training errors: 0.0010865326980992183\n",
      "Average of test errors: 0.9190000057220459\n",
      "Standard deviation of test errors: 0.012274641839515309\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "For a single trained model this is a way of seeing which test example was classified incorrectly."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "(model.predict(X_test)>0.5)==y_test"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True]])"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "plot_grid(raw_X_test[13])\n",
    "y[13]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0.])"
      ]
     },
     "metadata": {},
     "execution_count": 17
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Tuning hyperparameters"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Training the model is not enough. there are a lot of parameters to vary and doing it by hand is cumbersome so we can automate it a little bit. This function takes in various parameters in the training along with the data and it trains the neural network. It outputs the parameters used and the test accuracy to we can use it in a loop to find the best hyperparameters."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "def deep_nn(X, y, X_test, y_test, layer1=10, layer2=10, lambd=0.05, num_epochs=50):\n",
    "\n",
    "    # Initialize list of training and test errors\n",
    "    train_errors = []\n",
    "    test_errors = []\n",
    "\n",
    "\n",
    "    # Loop to run model many times and average over results\n",
    "\n",
    "    for i in range(15):\n",
    "\n",
    "        # Print iteration to make sure everything works\n",
    "        print(i, end=\"\\r\")\n",
    "        \n",
    "        # Initialize model\n",
    "        model = Sequential()\n",
    "\n",
    "        # Add hidden layer with 32 units and rlu activation. Add output layer with sigmoid activation.\n",
    "        model.add(Dense(layer1, activation='relu', kernel_regularizer=l2(lambd), input_dim=25**2))\n",
    "        model.add(Dense(layer2, activation='relu', kernel_regularizer=l2(lambd)))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "        # Compile model\n",
    "        model.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        # Fit model\n",
    "        model.fit(X, y, epochs=num_epochs, verbose=0)\n",
    "\n",
    "        # Add training and test errors to lists\n",
    "        train_errors.append(model.evaluate(X,y,verbose=0)[1])\n",
    "        test_errors.append(model.evaluate(X_test,y_test,verbose=0)[1])\n",
    "    \n",
    "    \n",
    "    print('Average of test errors for '+str(layer1)+' units in layer 1, '+str(layer2)+' units in layer 2, a regularization of '\n",
    "      +str(lambd)+' and '+str(num_epochs)+' epochs: '+str(np.mean(test_errors)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here we run the model for different values of the regularization parameter and it is clear that more regularization is better. There must be an upper bound at some point but it is not clear yet what it is."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "for lambd in [0, 0.05, 0.1]:\n",
    "            \n",
    "        deep_nn(X,y,X_test,y_test, lambd=lambd)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Average of test errors for 10 units in layer 1, 10 units in layer 2, a regularization of 0 and 50 epochs: 0.7696666677792867\n",
      "Average of test errors for 10 units in layer 1, 10 units in layer 2, a regularization of 0.05 and 50 epochs: 0.8606666684150696\n",
      "Average of test errors for 10 units in layer 1, 10 units in layer 2, a regularization of 0.1 and 50 epochs: 0.8993333299954732\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We train the model for different sizes of the first hidden layer to see how much it impacts the accuracy. It looks like a bigger layer increases pretty well the efficiency of the model. Increasing more could be even better, up to a point."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "for layer1 in [10, 15, 20]:\n",
    "    \n",
    "        deep_nn(X,y,X_test,y_test, layer1)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Average of test errors for 10 units in layer 1, 10 units in layer 2, a regularization of 0.05 and 50 epochs: 0.8890000025431315\n",
      "Average of test errors for 15 units in layer 1, 10 units in layer 2, a regularization of 0.05 and 50 epochs: 0.905999998251597\n",
      "Average of test errors for 20 units in layer 1, 10 units in layer 2, a regularization of 0.05 and 50 epochs: 0.9126666744550069\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we train the model for a different number of epochs and see that even if doing early stopping helps a little bit it is not the main solution, compared to regularization for example."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "for num_epochs in [40, 50, 60]:\n",
    "    \n",
    "    deep_nn(X,y,X_test,y_test, num_epochs=num_epochs)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Average of test errors for 10 units in layer 1, 10 units in layer 2, a regularization of 0.05 and 40 epochs: 0.8713333328564962\n",
      "Average of test errors for 10 units in layer 1, 10 units in layer 2, a regularization of 0.05 and 50 epochs: 0.8330000003178915\n",
      "Average of test errors for 10 units in layer 1, 10 units in layer 2, a regularization of 0.05 and 60 epochs: 0.8819999972979228\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Experiment with other data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## More data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "It's interesting to see if getting more data with the same parameters for the model will give better results so we generate new data to fit the model. The result is actually a little bit less accurate so we would need to tune more the parameters. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "raw_X, X, y = generate_data(size=25, num_temp=45, repeat=25)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "610\r"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "deep_nn(X, y, X_test, y_test, layer1=25, layer2=15, lambd=0.1, num_epochs=40)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Longer simulation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "One other thing to try is simulating the Ising model for a longer period of time. We keep the same amount of data as the original case but simulate longer and see if it is easier to classify the phases."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "raw_X, X, y = generate_data(size=25, num_temp=40, repeat=20, max_iter=10*25*25)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We first test the neural network on the old test set (simulated for a shorter time) to see how it reacts. The neural network seems to do worse."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "deep_nn(X, y, X_test, y_test, layer1=25, layer2=15, lambd=0.1, num_epochs=40)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can also check if evaluating the model on data that stops at the same time step is good. This should at least be better since the test set looks more like the training set and it indeed is better."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "raw_X_test, X_test, y_test = generate_data(size=25, num_temp=20, repeat=10, max_iter=10*25*25)\n",
    "deep_nn(X, y, X_test, y_test, layer1=25, layer2=15, lambd=0.1, num_epochs=40)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plot_grid(raw_X_test[10])\n",
    "y[10]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plot_grid(initialize_grid(25))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}